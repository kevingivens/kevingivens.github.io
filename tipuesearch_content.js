var tipuesearch = {"pages":[{"title":"About","text":"Hi! My name is Kevin Givens and welcome to my blog. I'm a quant living in New York City. Before working in finance, I earned a PhD in High Energy Physics. This blog is a place for me to study and share topics I find interesting. I hope you find them interesting as well. They will inevitably be a reflection of my interests in mathematics and computer science. About the title of the website, it's a reference to the Lyceum of Ancient Rome . This is the place where Aristotle founded the Peripetic school and lectured in philosophy. Like an aspiring member of the school, I'm trying to sort out ideas by walking around a bit. As usual, the views and opinions expressed here are my own and are not a reflection of my former and current employers.","tags":"pages","url":"/pages/about.html","loc":"/pages/about.html"},{"title":"Local Volatility in PyQL","text":"Summary: Local Volatility Surface in PyQL Following on my previous post , I wanted to review the important concept of Local Volatility. Many books and articles 1 , 2 are dedicated to discussing this topic. I won't go into great detail here, I just want to give a basic overview along with implementation details in PyQL. Essentially, the idea of Local Volatility is to identify a level-dependent diffusion that exactly reproduces market implied volatilities. The contribution of Dupire was to prove that this diffusion is unique while also providing a convenient technique for deriving it from market quotes. The full derivation of the local volatility function is given in section 2.2 and the appendix of 2 . Here, I'll just give a sketch of the approach. To begin, consider a generic, level-dependent , 1-D Brownian motion $$ \\frac{\\partial S}{S} = \\mu(t, S)\\partial t + \\sigma(t,S)\\partial W $$ Note that, the volatility for this process is not itself stochastic. We can use this process to model the diffusion on a equity spot price in the presence of a short rate \\(r(t)\\) and a dividend yield \\(D(t)\\) . A European call option for this process then satisfies a modified version of the Black-Scholes equation: $$ \\frac{\\partial{C}}{\\partial{t}} = \\frac{\\sigma&#94;2K&#94;2}{2}\\frac{\\partial&#94;2C}{\\partial K&#94;2} + (r(t) - D(t))\\left(C- K\\frac{\\partial{C}}{\\partial{K}}\\right) $$ We can simplify this equation by writing \\(C(S_0, K,T)\\) as a function of the forward price \\(F_T=S_0\\exp(\\int_0&#94;T\\mu(t)dt) = S_0\\exp(\\int_0&#94;T(r(t) - D(t))dt)\\) , (i.e. use the forward measure) In these units, Black-Scholes equation simplifies to $$ \\frac{\\partial C}{\\partial t} = \\frac{\\sigma&#94;2K&#94;2}{2}\\frac{\\partial&#94;2 C}{\\partial K&#94;2} $$ or solving for the volatility gives Dupire's equation $$ \\sigma&#94;2(K,T) = \\frac{\\frac{\\partial C}{\\partial T}}{\\frac{1}{2}K&#94;2\\frac{\\partial&#94;2 C}{\\partial K&#94;2}} $$ Market quotes are usually given in terms of Black-Scholes implied volatilities. We can express the local volatility in terms of these quantities by equating the price equations for the two models $$ C_{local}(S_0, K,T) = C_{BS}(S_0, K, \\sigma_{BS}, T) $$ The strategy is then to solve for the local volatility in terms of the Black-Scholes impliedvolatility since we have a closed form expression for the \\(C_{BS}\\) . The full derivation is given in section 2.2 of 2 . Here we just reproduce the results. Namely, using more convenient units, the Black-Scholes total variance $$ w(S_0,K,T) = \\sigma&#94;2_{BS}(S_0,K,T)T $$ and log-moneyness $$y = \\ln\\left(\\frac{K}{F_T}\\right)$$ We can show that the local variance $$v_{local} = \\sigma&#94;2(S_0, K,T)$$ satisfies the following expression: $$ v_{local} = \\frac{\\frac{\\partial w}{\\partial T}}{1 - \\frac{y}{w}\\frac{\\partial w}{\\partial y} + \\frac{1}{4}\\left(-\\frac{1}{4} - \\frac{1}{w} + \\frac{y&#94;2}{w&#94;2}\\right)\\left(\\frac{\\partial w}{\\partial y}\\right)&#94;2 + \\frac{1}{2}\\left(\\frac{\\partial&#94;2 w}{\\partial y&#94;2}\\right)} $$ Quantlib implements this equation in ql.termstructure.volatility.equityfx.localvolsurface In the code excerpt below we, show the LocalVolSurface is used in PyQL. It follows a similiar interface and BlackVarianceSurface given in the previous post . calc_date = Date ( 6 , 11 , 2015 ) Settings () . evaluation_date = calc_date risk_free_rate = 0.01 dividend_rate = 0.0 day_count = Actual365Fixed () calendar = UnitedStates () flat_ts = FlatForward ( calc_date , risk_free_rate , day_count ) dividend_ts = FlatForward ( calc_date , dividend_rate , day_count ) expiration_dates = [ Date ( 6 , 12 , 2015 ), Date ( 6 , 1 , 2016 ), Date ( 6 , 2 , 2016 ), Date ( 6 , 3 , 2016 ), Date ( 6 , 4 , 2016 ) ] strikes = [ 527.50 , 560.46 , 593.43 , 626.40 ] data = np . array ( [ [ 0.37819 , 0.34450 , 0.37419 , 0.37498 , 0.35941 ], [ 0.34177 , 0.31769 , 0.35372 , 0.35847 , 0.34516 ], [ 0.30394 , 0.29330 , 0.33729 , 0.34475 , 0.33296 ], [ 0.27832 , 0.27614 , 0.32492 , 0.33399 , 0.32275 ] ] ) vols = Matrix . from_ndarray ( data ) black_var_surf = BlackVarianceSurface ( calc_date , calendar , expiration_dates , strikes , vols , day_count ) spot = 659.37 strike = 600.0 expiry = 0.2 # years local_vol_surf = LocalVolSurface ( black_var_surf , flat_ts , dividend_ts , spot ) print ( \"local vol: \" , local_vol_surf . localVol ( expiry , strike )) In the plots below, we can see what the LocalVolSurface looks like: Take a look at the PyQL bindings on my github to see an example of the LocalVolSurface . See you next time. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; var configscript = document.createElement('script'); configscript.type = 'text/x-mathjax-config'; configscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" availableFonts: ['STIX', 'TeX'],\" + \" preferredFont: 'STIX',\" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript); (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"Finance","url":"/local-volatility-in-pyql.html","loc":"/local-volatility-in-pyql.html"},{"title":"Black Variance Surface in PyQL","text":"Summary: Building Black Variance Surfaces in PyQL In my previous post on Variance Swaps, I neglected to mention an important implementation detail. If you look the Variance Swap unittest or example script you'll see that replicating pricer requires a BlackVarianceSurface object. I had to build bindings for these in PyQL so I thought I'd mention how they work. BlackVarianceSurface is a volatility termstructure that implements different types of 2-d interpolation routines between implied volatility quotes. I included two types of interpolations from the Quantlib source code: Bilinear Bicubic To over simplify, Bilinear linearly interpolates between neighboring quotes. Bicubic uses a cubic spline routine (third order polynomial) to smoothly interpolate between points. See for wikipedia for a nice summary of the differences between bicubic vs. bilinear interpolation. The python interface is given in the example below ... dc = Actual365Fixed () calendar = UnitedStates () calculation_date = Date ( 6 , 11 , 2015 ) spot = 659.37 Settings . instance () . evaluation_date = calculation_date dividend_yield = SimpleQuote ( 0.0 ) risk_free_rate = 0.01 dividend_rate = 0.0 # bootstrap the yield/dividend/vol curves flat_term_structure = FlatForward ( reference_date = calculation_date , forward = risk_free_rate , daycounter = dc ) flat_dividend_ts = FlatForward ( reference_date = calculation_date , forward = dividend_yield , daycounter = dc ) dates = [ Date ( 6 , 12 , 2015 ), Date ( 6 , 1 , 2016 ), Date ( 6 , 2 , 2016 ), Date ( 6 , 3 , 2016 ), ] strikes = [ 527.50 , 560.46 , 593.43 , 626.40 ] data = np . array ( [ [ 0.37819 , 0.34177 , 0.30394 , 0.27832 ], [ 0.3445 , 0.31769 , 0.2933 , 0.27614 ], [ 0.37419 , 0.35372 , 0.33729 , 0.32492 ], [ 0.34912 , 0.34167 , 0.3355 , 0.32967 ], [ 0.34891 , 0.34154 , 0.33539 , 0.3297 ] ] ) vols = Matrix . from_ndarray ( data ) # Build the Black Variance Surface black_var_surf = BlackVarianceSurface ( calculation_date , NullCalendar (), dates , strikes , vols , dc ) strike = 600.0 expiry = 0.2 # years # The Surface interpolation routine can be set below (Bilinear is default) black_var_surf . set_interpolation ( Bilinear ) print ( \"black vol bilinear: \" , black_var_surf . blackVol ( expiry , strike )) black_var_surf . set_interpolation ( Bicubic ) print ( \"black vol bicubic: \" , black_var_surf . blackVol ( expiry , strike )) As a sanity checked, I re-implemented results from an excellent blog post by Gouthaman Balaraman. In that post, the author builds a BlackVarianceSurface object using Quantlib's swig bindings. The plots for the same market data are given below: For Bilinear interpolation, the surface looks like For Bicubic interpolation, the surface looks like As you can see from the plots, the bicubic is slightly smoother than bilinear. Take a look at the PyQL bindings on my github page to see how the BlackVarianceSurface is implemented. The script to generate the plots is here One thing that I clearly need to improve is the flexibility on the volatility data structure input to the BlackVarianceSurface constructor. It would be better to allow the vols data structure to be either a list of lists, a numpy array, or a QL Matrix object. I'll try to fix that at some point. See you next time.","tags":"Finance","url":"/black-variance-surface-in-pyql.html","loc":"/black-variance-surface-in-pyql.html"},{"title":"Variance Swaps in PyQL","text":"Summary: We review the Variance Swap replicating pricer in QuantLib and its implementation in PyQL Introduction Recently, I had the opportunity to extend the PyQL library to include variance swaps pricers. I thought I'd take the chance to review the pricing of Variance Swaps in Quantlib (to refresh my own memory if nothing else). As a reminder, a variance swap is a forward contract on realized variance, i.e. it has the following payoff at maturity $$ N(\\sigma_R&#94;2{\\tau} - K) $$ Where \\(N\\) is the notional, \\(\\sigma_R&#94;2{\\tau}\\) is the realized variance at maturity, \\(\\tau\\) , and \\(K\\) is the strike. This instrument can be used to provide pure exposure to variance. This is different then, for instance, a vanilla option which has variance (or volatility) exposure but also includes exposure to other risk factors such as the spot risk (delta). Quantlib includes two different pricing engines, ReplicatingVarianceSwapEngine and MCVarianceSwapEngine . As you might have guessed, ReplicatingVarianceSwapEngine uses a replicating portfolio to price a VarianceSwap and MCVarainceSwapEngine uses a Monte Carlo simulation. For this post, I'm going to focus on the replicating engine as the MCEngine is conventional and not terribly interesting. The replicating portfolio technique is described in thorough detail in Derman In essence, the idea of this (or any) replicating pricer is to reproduce the payoff of the variance swap using a portfolio of liquid vanilla instruments. In Derman , the authors show that a replicating portfolio can be constructed from a weighted combination of European Calls and Puts. We derive this portfolio in the next section. The derivation the the replicating portfolio is somewhat indirect. The authors introduce a fictitious instrument known as log contract that exactly replicates the variance swap payoff. They then show that the log contract can itself be replicated by the particular combination of European puts and calls. That being said, the Quantlib implementation is pretty straight forward. I directly adapted the variance swap unittests from Quantlib into PyQL ( tests/test_variance_swap.py ) You can find an example variance swap using the ReplicatingVarianceSwapEngine in that script. The important sections are given below # The Variance Swap is constructed #Type, Strike, Notional, Start, End strike = 0.04 notional = 50000 start = today () end = start + int ( 0.246575 * 365 + 0.5 ) # This is weird value but it was in the Quantlib unittest var_swap = VarianceSwap ( SwapType . Long , 0.04 , 50000 , start , end ) # Option Data used in the replicating engine replicating_option_data = [ { 'type' : OptionType . Put , 'strike' : 50 , 'v' : 0.30 }, { 'type' : OptionType . Put , 'strike' : 55 , 'v' : 0.29 }, { 'type' : OptionType . Put , 'strike' : 60 , 'v' : 0.28 }, { 'type' : OptionType . Put , 'strike' : 65 , 'v' : 0.27 }, { 'type' : OptionType . Put , 'strike' : 70 , 'v' : 0.26 }, { 'type' : OptionType . Put , 'strike' : 75 , 'v' : 0.25 }, { 'type' : OptionType . Put , 'strike' : 80 , 'v' : 0.24 }, { 'type' : OptionType . Put , 'strike' : 85 , 'v' : 0.23 }, { 'type' : OptionType . Put , 'strike' : 90 , 'v' : 0.22 }, { 'type' : OptionType . Put , 'strike' : 95 , 'v' : 0.21 }, { 'type' : OptionType . Put , 'strike' : 100 , 'v' : 0.20 }, { 'type' : OptionType . Call , 'strike' : 100 , 'v' : 0.20 }, { 'type' : OptionType . Call , 'strike' : 105 , 'v' : 0.19 }, { 'type' : OptionType . Call , 'strike' : 110 , 'v' : 0.18 }, { 'type' : OptionType . Call , 'strike' : 115 , 'v' : 0.17 }, { 'type' : OptionType . Call , 'strike' : 120 , 'v' : 0.16 }, { 'type' : OptionType . Call , 'strike' : 125 , 'v' : 0.15 }, { 'type' : OptionType . Call , 'strike' : 130 , 'v' : 0.14 }, { 'type' : OptionType . Call , 'strike' : 135 , 'v' : 0.13 }, ] # The engine is constructed engine = ReplicatingVarianceSwapEngine ( process , call_strikes , put_strikes , 5.0 ) # dK, shift below lowest put strike # attach the engine to the swap var_swap . set_pricing_engine ( engine ) print ( \"strike: \" , var_swap . strike ) print ( \"postion: \" , var_swap . position ) print ( \"variance: \" , var_swap . variance ) The output is: strike : 0.04 postion : SwapType . Long variance : 0.0419 Deriving the Replicating Portfolio Briefly, from the definition of the variance strike given above, we see that the par strike of a variance swap is the expected realized variance, i.e. $$ K_{var} = \\frac{1}{T}\\mathbf{E}\\left[\\int&#94;T_0 \\sigma&#94;2(t, \\dots)dt\\right] $$ The first step in the derivation is to re-write this expression. We consider a generic Ito process of the following form: $$\\frac{dS_t}{S_t} = \\mu(t, \\dots) dt + \\sigma(t, \\dots) dW_t $$ Where \\(\\mu\\) and \\(\\sigma\\) can be time or level dependent. Applying Ito's lemma to \\(\\ln(S_t)\\) and subtracting the above equation gives $$\\frac{dS_t}{S_t} - d\\left(\\ln(S_t)\\right) = \\frac{1}{2}\\sigma&#94;2dt$$ We insert this expression into the \\(K_{var}\\) definition to get $$ \\begin{align} K_{var} =& \\frac{2}{T}\\mathbf{E}\\left[\\int&#94;T_0 \\frac{\\partial S_t}{S_t} - \\ln\\left(\\frac{S_T}{S_0}\\right)\\right] \\\\ \\end{align} $$ Next, we partition the strike domain by introducing a cutoff strike value, \\(S_* \\in (0, \\infty)\\) . In what follows this cutoff will be set to lower bound of put strikes, but for now we leave it arbitrary. The allows us the write \\(K_{var}\\) as $$ \\begin{align} K_{var} =& \\frac{2}{T}\\mathbf{E}\\left[\\int&#94;T_0 \\frac{\\partial S_t}{S_t} - \\frac{S_T- S_*}{S_*}- \\ln\\left(\\frac{S_*}{S_0}\\right) + \\frac{S_T- S_*}{S_*} -\\ln\\left(\\frac{S_T}{S_*}\\right)\\right] \\end{align} $$ We can then use the fact that in the risk neutral measure $$ \\mathbf{E}\\left[\\int&#94;T_0 \\frac{\\partial S_t}{S_t}dt\\right] = rT $$ (i.e. martingales are driftless) Distributing the expectation value gives $$ K_{var} = \\frac{2}{T}\\left[rT - \\left(\\frac{S_0}{S_*}e&#94;{rT} - 1\\right) - \\ln\\left(\\frac{S_*}{S_0}\\right)\\right] + e&#94;{rT}\\frac{2}{T}\\mathbf{E}\\left[ \\frac{S_T- S_*}{S_*} -\\ln\\left(\\frac{S_T}{S_*}\\right)\\right] $$ This expression implies that the variance swap can be replicated by an option with the following payoff $$ f(S_T) = \\frac{2}{T}\\left(\\frac{S_T-S_*}{S_*} - \\ln\\frac{S_T}{S_*}\\right) \\label{eq1} $$ This option is the so-called log-contract , which obviously only exists in the minds of quants. The final trick to recognize that the log-contract can itself be replicated as linear combination of European calls and puts (which thankfully do exist!). We first consider the strike, \\(K\\) , as a continuous variable. We then can build a portfolio that matches the log contract's payoff by weighting the options with the inverse of their strikes. Namely, we can show that $$ \\frac{S_T- S_*}{S_*} -\\ln\\left(\\frac{S_T}{S_*}\\right) = \\int&#94;{S_*}_0 dK\\frac{\\max[K- S(T),0]}{K&#94;2} + \\int_{S_*}&#94;{\\infty} dK\\frac{\\max[S(T)- K, 0]}{K&#94;2} $$ So we can approximate the price of the log-contract by expanding the expectation value as a sum of European calls and puts $$ \\begin{align} \\mathbf{E}\\left[ \\frac{S_T- S_*}{S_*} -\\ln\\left(\\frac{S_T}{S_*}\\right)\\right] &= \\mathbf{E}\\left[ \\int&#94;{S_*}_0 dK\\frac{\\max[K- S(T),0]}{K&#94;2} + \\int_{S_*}&#94;{\\infty} dK\\frac{\\max[S(T)- K, 0]}{K&#94;2} \\right] \\\\ & =\\int&#94;{S_*}_0 \\frac{dK}{K&#94;2} \\mathbf{E}\\left[\\max[K- S(T),0]\\right] + \\int_{S_*}&#94;{\\infty} \\frac{dK}{K&#94;2}\\mathbf{E}\\left[\\max[S(T)- K, 0]\\right] \\\\ & =\\int&#94;{S_*}_0 \\frac{dK}{K&#94;2} P(K,T) + \\int_{S_*}&#94;{\\infty} \\frac{dK}{K&#94;2}C(K,T) \\\\ \\end{align} $$ \\(S_*\\) is then set to the put strike lower bound, \\(S_* = K_{Put_1} - dK\\) . In the numerical example given above \\(S_* = 50 - 5 = 45\\) . Take a look at the PyQL bindings on my github page to see how the ReplicatingVarianceSwapEngine is implemented. See you next time. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; var configscript = document.createElement('script'); configscript.type = 'text/x-mathjax-config'; configscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" availableFonts: ['STIX', 'TeX'],\" + \" preferredFont: 'STIX',\" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript); (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"Finance","url":"/variance-swaps-in-pyql.html","loc":"/variance-swaps-in-pyql.html"},{"title":"Simulating the Heston Process","text":"Summary: We investigate different discretization schemes for the Heston Process, looking at issues of numerical bias and ease of implementation In today's post, I will examine a few issues related to numerical simulation of the Heston model. As a quick reminder, the Heston process is a stochastic volatility model defined by the following sde: $$ dS_t = (r-d) S_t dt + \\sqrt{V_t} S_t dW&#94;s_t $$ $$ dV_t = \\kappa (\\theta - V_t) dt + \\sigma \\sqrt{V_t} dW&#94;\\upsilon_t $$ $$ dW&#94;s_t dW&#94;\\upsilon_t = \\rho dt $$ for asset price \\(S_t\\) . \\(dW_t&#94;s\\) and \\(dW_t&#94;{\\nu}\\) are Wiener processes with correlation \\(\\rho\\) . As usual, \\(r\\) and \\(d\\) are the risk free and dividend rates respectively. The Heston model is an excellent benchmarking model due to the suprising fact that that it's probability distribution function (pdf) has a closed formed expression. It's a one of five such processes in 1 or 2 dimensions PHL . With the closed form pdf, we can easily compare the performance of the Heston model's numerical simulation by comparing PV's of a Monte Carlo pricer with an analytic pricer. To carry out a numerical simulation we first need to choose a discretization scheme. That is, we need to approximate the infinitesimal diffusion process with a finite scheme to be used in the simulation code. Any such scheme may potentially introduce bias into the simulation that could alter the realized moments of the pdf. The simplest possible scheme is a first order expansion, i.e. an Euler Mayorana (or just ''Euler'') scheme. Transforming to \\(\\ln S\\) and discretizing \\(t\\) to step size \\(\\Delta\\) gives $$ \\ln S(t + \\Delta) = \\ln S(t) + \\left(r - d - \\frac{1}{2}V(t)\\right)\\Delta +\\sqrt{V(t)} Z_S\\sqrt{\\Delta} $$ $$ V(t + \\Delta) = V(t) + \\kappa\\left(\\theta - V(t)\\right)\\Delta + \\sigma \\sqrt{V(t)} Z_V \\sqrt{\\Delta} $$ However, it turns out that this scheme does introduce bias. Furthermore, in this scheme it's possible to drive the variance process to negative values, which is outside the range of the pdf and causes the simulation to stop as \\(\\sqrt{V}\\) becomes imaginary. One immediate fix to this problem is the floor V at 0, giving the so called \"Truncated\" scheme. Other schemes are based on higher order expansions of the sde or utilizing the closed form expression for the pdf. These are documented extensively in the literature Anderson . We list some of the schemes below Euler Mayorana Truncated Quadratic Exponential Broadie Kaya (Exact Simulation) Broadie Kaya is based off direct sampling from the pdf but is rather difficult to implement numerically. The Quadratic Exponential (developed in Anderson ) approximates the pdf using simplified functions and moment matching. The pdf for high and low values of the variance are matched against two different functions and threshold is implemented to switch between the two functions during a diffusion. This technique allows one to minimize variance while also easing the numerical implementation. As such, this scheme it is often the preferred scheme for Heston simulations. QuantLib Implementation QuantLib includes several of these discretization schemes in their Heston Process class. Let's see what a simulation looks like. Quick note: Although the HestonProcess class is available through the SWIG bindings, it does not expose the discretizations argument. Instead, we use PyQL , which has all the discretizations available. from quantlib.processes.heston_process import * from quantlib.quotes import SimpleQuote from quantlib.settings import Settings from quantlib.termstructures.yields.flat_forward import FlatForward from quantlib.time.api import today , TARGET , ActualActual , Date , Period , Years from quantlib.models.equity.heston_model import ( HestonModel , HestonModelHelper ) from quantlib.pricingengines.api import ( AnalyticHestonEngine ) from quantlib.pricingengines.vanilla.mceuropeanhestonengine import MCEuropeanHestonEngine from quantlib.instruments.api import ( PlainVanillaPayoff , EuropeanExercise , VanillaOption , EuropeanOption ) Defining the Heston Process def flat_rate ( forward , daycounter ): return FlatForward ( forward = forward , settlement_days = 0 , calendar = TARGET (), daycounter = daycounter ) settings = Settings . instance () settlement_date = today () settings . evaluation_date = settlement_date day_counter = ActualActual () interest_rate = 0.7 dividend_yield = 0.4 risk_free_ts = flat_rate ( interest_rate , day_counter ) dividend_ts = flat_rate ( dividend_yield , day_counter ) maturity = Period ( 10 , Years ) exercise_date = settlement_date + maturity # spot s0 = SimpleQuote ( 100.0 ) # Available descritizations #PARTIALTRUNCATION #FULLTRUNCATION #REFLECTION #NONCENTRALCHISQUAREVARIANCE #QUADRATICEXPONENTIAL #QUADRATICEXPONENTIALMARTINGALE #BROADIEKAYAEXACTSCHEMELOBATTO #BROADIEKAYAEXACTSCHEMELAGUERRE #BROADIEKAYAEXACTSCHEMETRAPEZOIDAL # Heston Model params v0 = 0.05 kappa = 5.0 theta = 0.05 sigma = 1.0e-4 rho = - 0.5 def gen_process ( desc ): process = HestonProcess ( risk_free_ts , dividend_ts , s0 , v0 , kappa , theta , sigma , rho , desc ) return process processes = { \"REFLECTION\" : gen_process ( REFLECTION ), \"PARTIALTRUNCATION\" : gen_process ( PARTIALTRUNCATION ), \"QUADRATICEXPONENTIAL\" : gen_process ( QUADRATICEXPONENTIAL ), \"QUADRATICEXPONENTIALMARTINGALE\" : gen_process ( QUADRATICEXPONENTIALMARTINGALE ), } Visualizing the Simulation Note: The simulate function is not part of Quantlib. It has been added to the PyQL interface (see folder quantlib/sim ). from quantlib.sim.simulate import simulate_process from quantlib.time_grid import TimeGrid import pandas as pd import numpy as np import matplotlib.pyplot as plt % matplotlib inline import seaborn as sns sns . set ( style = \"white\" , rc = { \"axes.facecolor\" : ( 0 , 0 , 0 , 0 )}) # simulate and plot Heston paths paths = 200 steps = 100 horizon = 2 seed = 154 grid = TimeGrid ( horizon , steps ) fig , axs = plt . subplots ( figsize = ( 14 , 12 ), nrows = 2 , ncols = 2 ) flat_axs = axs . reshape ( - 1 ) for i , key in enumerate ( processes . keys ()): flat_axs [ i ] . plot ( list ( grid ), simulate_process ( processes [ key ], paths , grid , seed )) flat_axs [ i ] . set_xlabel ( 'Time' ) flat_axs [ i ] . set_ylabel ( 'Stock Price' ) flat_axs [ i ] . set_title ( ' %s ' % key ) Let's look at of the diffusions in detail, for example the evolution of the Heston process using Partial Truncation looks like this res = simulate_process ( processes [ \"PARTIALTRUNCATION\" ], paths , grid , seed ) x = res [[ 25 , 50 , 75 , 100 ],:] . reshape ( 4 * paths ) g = np . repeat ([ \"T=0.5\" , \"T=1.0\" , \"T=1.5\" , \"T=2.0\" ], paths ) df = pd . DataFrame ( dict ( x = x , g = g )) # Initialize the FacetGrid object pal = sns . cubehelix_palette ( 10 , rot =-. 25 , light =. 7 ) g = sns . FacetGrid ( df , row = \"g\" , hue = \"g\" , aspect = 10 , size = 1.6 , palette = pal ) g . map ( sns . distplot , \"x\" , bins = 40 , kde = True , rug = False ) g . map ( plt . axhline , y = 0 , lw = 2 , clip_on = False ) def label ( x , color , label ): ax = plt . gca () ax . text ( 0 , . 3 , label , fontweight = \"bold\" , color = color , ha = \"left\" , va = \"center\" , transform = ax . transAxes ) g . map ( label , \"x\" ) g . fig . subplots_adjust ( hspace =. 25 ) g . set_titles ( \"\" ) g . set ( yticks = []) g . despine ( bottom = True , left = True ) Comparing the PV's of different engines To examine the performance of the numerical schemes, we simply compare the PV's the same Call Option priced with an analytic and Monte Carlo engine. The results for different time steps and schemes are given in the table below # Build a Call Option payoff = PlainVanillaPayoff ( 'Call' , 105 ) exercise = EuropeanExercise ( exercise_date ) option = EuropeanOption ( payoff , exercise ) results = { \"REFLECTION\" : [], \"PARTIALTRUNCATION\" : [], \"QUADRATICEXPONENTIAL\" : [], \"QUADRATICEXPONENTIALMARTINGALE\" : [], } # steps per year steps = [ 1 , 4 , 8 , 16 ] for k , v in processes . items (): for step in steps : mc_engine = MCEuropeanHestonEngine ( v , steps_per_year = step , required_samples = 500 , seed = 1234 , ) option . set_pricing_engine ( mc_engine ) results [ k ] . append (( np . around ( option . npv , 5 ), np . around ( option . error_estimate , 5 ))) results [ \"time steps per year\" ] = steps results_df = pd . DataFrame ( data = results ) cols = results_df . columns . tolist () cols = cols [ - 1 :] + cols [ - 2 : - 1 ] + cols [: - 2 ] results_df = results_df [ cols ] results_df time steps per year REFLECTION PARTIAL TRUNCATION QUADRATIC EXPONENTIAL QUADRATIC EXPONENTIAL MARTINGALE 1 (1.64404, 0.05392) (1.74109, 0.03607) (1.71144, 0.02744) (1.71527, 0.02811) 4 (1.64447, 0.06608) (1.74109, 0.03607) (1.71144, 0.02744) (1.71527, 0.02811) 8 (1.98966, 0.04768) (1.77399, 0.03692) (1.70905, 0.02727) (1.73049, 0.02829) 16 (1.80227, 0.03563) (1.75864, 0.0351) (1.70581, 0.02687) (1.72956, 0.02818) Conclusion As we saw, there are many ways to simulate the Heston model, each with strengths and weaknesses with regards to bias/accuracy and runtime performance. In general, the Quadratic Exponential scheme performed better than Euler-type schemes, especially for simulations with fewer time steps per year. In a future post, I will visit the local stochastic volatility version of the Heston model to see how it's simulation works. Is there a better way? If you take a look at the HestonProcess class file in QuantLib you will see that it, for each discretization, there is a different diffusion implementation. The user chooses the discretization from an enumerated list. The downside to this approach is that , in addition to creating bloated code, the list is always finite. What happens when someone wants to create a new discretization scheme that's not on the list? She has to add the diffusion implementation directly into the HestonProcess class. A better approach might be to allow the user to build her own discretization in Python and then \"compile-down\" to C++ in the similar way to how the finite difference stencils are created in Devito [see my earlier post] This may just be hopeful speculation on my part :). Until next time. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; var configscript = document.createElement('script'); configscript.type = 'text/x-mathjax-config'; configscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" availableFonts: ['STIX', 'TeX'],\" + \" preferredFont: 'STIX',\" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript); (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"Finance","url":"/simulating-the-heston-process.html","loc":"/simulating-the-heston-process.html"},{"title":"Devito and Option Pricing","text":"Summary: Devito allows users to build finite difference schemes in python and \"compile-down\" to optimized C++ Finite difference methods have a long history in quantitative finance. They are the preferred technique to price and risk manage instruments based on low dimensional probabilistic models that lack analytic solutions. To implement the finite difference method, one chooses a discretization scheme (or stencil) that approximates the derivatives in the model. This scheme converts a system of differential equations into a system of algebraic equations that can be solved numerically. Naturally, a scheme introduces error into the calculation that is roughly proportional to the order of the discretization. Higher order schemes decrease the error in the system but are more difficult to implement by hand in compiled numerical code. Most option pricing libraries provide utilities for building common, low-order schemes. For instance, QuantLib provides forward, backward and central difference operators that can be combined to build a finite difference pricing engine for a given model. A new python library called Devito takes a different approach to finite difference model building. Instead of building a discretization scheme directly in C++, it instead allows users to build an arbitrary scheme in python and \"compile\" that scheme down to optimized C++. This code can either be JIT compiled and executed immediately or retained for later execution. In order to make this approach possible, Devito leverages Sympy, the python-based computer algebra system. Devito uses Sympy to algebraically manipulate the system of differential equations and generates the equivalent stencil equations used in the numerical implementation. It then generates optimized C++ code after passing the stencil equations through various optimization algorithms. This approach is equivalent to what happens in a compiler. To wit, \"high-level\" code is parsed, passed through optimization algorithms and printed down to \"low-level\" code. In this example, python is the high level code and C++ is the low level code. This approach has several advantages; one, the python implementation is close to the mathematical language; two, the often tedious algebraic manipulations needed to build the stencil is off-loaded to the computer algebra system (Sympy); three, the C++ implementation can be highly optimized of efficient computation. Black Scholes Equation As a first example, let's implement a finite difference solution of the Black Scholes model, the Hello World of quant finance. The Black Scholes PDE for a European option with strike, K, spot, S, volatility \\(\\sigma\\) , risk free rate, r, expiring at T, is given by $$ \\frac{\\partial V}{\\partial t} + \\frac{\\sigma&#94;2S&#94;2}{2}\\frac{\\partial &#94;2 V}{\\partial S&#94;2} + rS\\frac{\\partial V}{\\partial S} - rV = 0 $$ with the terminal condition for a Call option given by $$V(S,T) = \\max(S-K,0)$$ This PDE can be solved analytically: $$V(S,K,t,r, \\sigma)=SN(d_1)−Ke&#94;{−rt}N(d_2)$$ $$d_1=\\frac{\\ln\\left(\\frac{S}{K}\\right)+\\left(r+0.5\\sigma&#94;2\\right)T}{\\sigma\\sqrt{T}}\\,\\,\\,d_2=d_1−\\sigma\\sqrt{T}$$ In Numpy, this pricing function is import numpy as np from scipy.stats import norm import matplotlib.pyplot as plt % matplotlib inline #Black Scholes Formula def d1 ( S0 , K , r , sigma , t ): return ( np . log ( S0 / K ) + ( r + sigma ** 2 / 2 ) * t ) / ( sigma * np . sqrt ( t )) def d2 ( S0 , K , r , sigma , t ): return ( np . log ( S0 / K ) + ( r - sigma ** 2 / 2 ) * t ) / ( sigma * np . sqrt ( t )) def BlackScholes ( S0 , K , r , sigma , T ): return S0 * norm . cdf ( d1 ( S0 , K , r , sigma , T )) - K * np . exp ( - r * T ) * norm . cdf ( d2 ( S0 , K , r , sigma , T )) BS Finite Difference Scheme in Numpy In order to solve the BS PDE using finite difference techniques, we need to choose a discretization scheme. Keeping things simple, we choose central differences in space and forward differencing in time. Indexing the spatial dimension with \\(i\\) and the temporal dimension with \\(n\\) , Black Scholes PDE then becomes $$V_{i}&#94;{n+1} = V_{i}&#94;n - \\frac{\\sigma&#94;2 (i\\Delta S)&#94;2 \\Delta t}{2\\Delta S&#94;2}\\left(V_{i+1}&#94;n - 2 V_{i}&#94;n + V_{i-1}&#94;n\\right) - r(i\\Delta S)\\frac{\\sigma \\Delta t}{2\\Delta S}\\left(V_{i+1}&#94;n- V_{i-1}&#94;n \\right) + r \\Delta t V_{i}&#94;n$$ $$ = V_{i}&#94;n - \\frac{\\sigma&#94;2 (i)&#94;2 \\Delta t}{2}\\left(V_{i+1}&#94;n - 2 V_{i}&#94;n + V_{i-1}&#94;n\\right) -r(i)\\frac{\\sigma\\Delta t}{2}\\left(V_{i+1}&#94;n- V_{i-1}&#94;n \\right)+ r \\Delta t V_{i}&#94;n $$ Let's first implement a Numpy version of the scheme for comparison's sake. The numerical algorithm essentially works as follows Evaluate the pricing function at the boundary (payoff) Iterate backwards in time, solving the difference equation at each iteration Terminate at t=0 (the evaluation date) to obtain the present value (PV) In terms of data structures, all we need in order to implement this algorithm is two Numpy array buffers. A word on spatial boundary conditions We need to choose spatial boundary conditions on pricing function. In practice, this means enforcing some conditions on either the pricing function itself or derivatives of the pricing function. Following Wilmott Vol 3 , we choose the following boundary conditions For \\(S = 0 \\;\\; \\frac{\\partial V}{\\partial t}(0,t) - rV(0,t) = 0\\) In discrete form this becomes: $$V_n&#94;0 = (1 - r \\delta t) V_{k-1}&#94;0$$ For \\(S = S_{max}\\;\\; \\frac{\\partial&#94;2 V}{\\partial S&#94;2}(S,t) = 0\\) In discrete form this becomes: $$V_n&#94;i = 2V_n&#94;{i-1} - V_n&#94;{i-2}$$ In principle, one can choose different boundary conditions without greatly effecting the computed pricing functions. For the remaining variables needed to solve the problem we make the following choices # Some variable declarations needed for numerical implementation nx = 20 # number of space steps s = 0.2 # vol r = 0.05 # interest rate T = 1 # time to expiry K = 100 # Strike dt = ( 0.9 / ( s * nx ) ** 2 ) # time step size nt = int ( T / dt ) + 1 # number of time steps dt = T / nt dx = 2 * K / nx Defining a Call payoff function and initializing it at the t=T boundary def payoff ( S , K ): return np . maximum ( S - K , 0 ) v_payoff = np . vectorize ( payoff ) v_bs = np . vectorize ( BlackScholes ) # Init C at the payoff S = np . arange ( 0 ,( nx + 1 ) * dx , dx ) C = v_payoff ( S , K ) Now we can define a diffuse function that carries out the finite difference algorithm. Here we name our pricing function C for Call in order to distinguish it from V used below in the Devito implementation. def diffuse ( C , nt ): for n in range ( nt ): Cn = C . copy () delta = ( 0.5 / dx ) * ( Cn [ 2 :] - Cn [ 0 : - 2 ]) gamma = ( 1 / ( dx ** 2 )) * ( Cn [ 2 :] - 2 * Cn [ 1 : - 1 ] + Cn [ 0 : - 2 ]) theta = - ( 0.5 * s ** 2 ) * np . multiply ( np . square ( S [ 1 : - 1 ]), gamma ) - r * np . multiply ( S [ 1 : - 1 ], delta ) + r * Cn [ 1 : - 1 ] C [ 1 : - 1 ] = Cn [ 1 : - 1 ] - dt * theta #spatial bc's C [ 0 ] = Cn [ 0 ] * ( 1 - r * dt ) C [ nx - 1 ] = 2 * C [ nx - 2 ] - C [ nx - 3 ] With our implementation in place, let's diffuse the model back 10 time steps. diffuse ( C , nt = 10 ) Comparing this to analytic solution to BS gives C array([ 0.00000000e+00, 6.77083365e-15, 2.47797465e-11, 1.38986768e-08, 2.31379196e-06, 1.50919507e-04, 4.48551091e-03, 6.67669285e-02, 5.33585468e-01, 2.44970519e+00, 7.05423863e+00, 1.43368053e+01, 2.32467881e+01, 3.28816476e+01, 4.27765661e+01, 5.27502671e+01, 6.27445527e+01, 7.27434913e+01, 8.27433082e+01, 9.27431251e+01, 1.00000000e+02]) v_bs ( S0 = S , K = 100 , r = r , sigma = s , T = 10 * dt ) array([ 0.00000000e+00, 2.13184792e-53, 8.12368101e-27, 1.49012572e-15, 1.86102962e-09, 8.60357129e-06, 1.81033147e-03, 5.89084888e-02, 5.84232552e-01, 2.66791893e+00, 7.33121846e+00, 1.45076224e+01, 2.33168378e+01, 3.29033374e+01, 4.27809370e+01, 5.27490737e+01, 6.27415850e+01, 7.27399614e+01, 8.27396309e+01, 9.27395669e+01, 1.02739555e+02]) Plotting the PV gives reasonable looking results fig , ax = plt . subplots () ax . plot ( S , C ) Devito Implementation Now we want to implement the same model in Devito. First, a brief word about the Devito API. (For more info, consult the Devito documentation) A key idea in Devito is to present users with a Function object that has dual identity, one symbolic and the other numeric. That is, Function objects can be manipulated by Sympy in order to generate the stencil equations. Later, when the finite difference scheme is being numerically solved, Function objects hold numerical data in two Numpy array buffers in similar way to how data was stored during the Numpy implementation given above. This dual approach allows users to implement and solve the finite difference problems in a natural way. They don't have to implement and reason about separate data structures for the differential equations as well as the numerical implementation. For our implementation, we first need to declare instances of Grid , Function and TimeFunction (time varying function). We then define the stencil equation using the TimeFunction V 's Sympy identity. from devito import Grid , TimeFunction , Function , Operator from sympy import Eq , solve # Initialize `u` for space order 2 grid = Grid ( shape = ( nx + 1 ,), extent = ( 200. ,)) V = TimeFunction ( name = 'V' , grid = grid , space_order = 2 ) X = Function ( name = 'X' , grid = grid ) # Create an equation with second-order derivatives eq = Eq ( V . dt , 0.5 * s ** 2 * X * X * ( V . dx2 ) + r * X * ( V . dx ) - r * V ) stencil = solve ( eq , V . forward )[ 0 ] eq_stencil = Eq ( V . forward , stencil ) Looking at the stencil, one can see that it is equivalent to the Numpy version of the stencil defined earlier. print ( stencil ) (0.025*dt*h_x*(-V(t, x - h_x) + V(t, x + h_x))*X(x) + 0.02*dt*(-2.0*V(t, x) + V(t, x - h_x) + V(t, x + h_x))*X(x)**2 + 0.05*h_x**2*(-dt + 20.0)*V(t, x))/h_x**2 Next we implement boundary conditions by setting the Data attribute of V equal to the payoff value. We also enforce spatial boundary conditions as before. Finally, we construct an Operator object from the stencil and boundary conditions. This is the object that carries out the diffusion in order to solve the finite difference problem. # Init C at the payoff S = np . arange ( 0 ,( nx + 1 ) * dx , dx ) V . data [ 0 ] = v_payoff ( S , K ) V . data [ 1 ] = v_payoff ( S , K ) X . data [:] = S # Create boundary condition expressions x = grid . dimensions t = grid . stepping_dim bc = [ Eq ( V . indexed [ t + 1 , 0 ], V . indexed [ t , 0 ] * ( 1 - r * dt ))] # bottom bc += [ Eq ( V . indexed [ t + 1 , - 1 ], 2 * V . indexed [ t + 1 , - 2 ] - V . indexed [ t + 1 , - 3 ])] # top # Define the operator op = Operator ([ eq_stencil ] + bc ) The data arrays before simulation are initialized to the payoff boundary V . data [ 1 ] array([ 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 10., 20., 30., 40., 50., 60., 70., 80., 90., 100.], dtype=float32) Diffusing the operator 10 time steps as before we get op ( time = 10 , dt = dt ) CustomCompiler : compiled /tmp/devito-oebkv76j/ 41 acee72a2d7a564a563c14bcd4b5358a3ed3147 . c [ 1.23 s ] ========================================================================================= Section section_0 < 10 , 20 > with OI = 1.44 computed in 0.000 s [ 4.00 GFlops / s ] Section main < 10 > with OI = 1.67 computed in 0.000 s [ 0.11 GFlops /s, 0.01 GPts/s ] ========================================================================================= Now let's inspect the data array V . data [ 0 ] array([ 0.00000000e+00, 6.77083621e-15, 2.47797494e-11, 1.38986778e-08, 2.31379227e-06, 1.50919528e-04, 4.48551122e-03, 6.67669326e-02, 5.33585429e-01, 2.44970512e+00, 7.05423832e+00, 1.43368015e+01, 2.32467213e+01, 3.28807259e+01, 4.27697105e+01, 5.27169189e+01, 6.26308594e+01, 7.24206314e+01, 8.20446320e+01, 9.12274399e+01, 1.00405121e+02], dtype=float32) Comparing that with the Numpy implementation gives similar results C array([ 0.00000000e+00, 6.77083365e-15, 2.47797465e-11, 1.38986768e-08, 2.31379196e-06, 1.50919507e-04, 4.48551091e-03, 6.67669285e-02, 5.33585468e-01, 2.44970519e+00, 7.05423863e+00, 1.43368053e+01, 2.32467881e+01, 3.28816476e+01, 4.27765661e+01, 5.27502671e+01, 6.27445527e+01, 7.27434913e+01, 8.27433082e+01, 9.27431251e+01, 1.00000000e+02]) As one can see from the results, the closest agreement between all three solutions is away from the boundaries and the cusp S = K. This makes sense as the pricing function isn't smooth at those points. I will explore the numerical errors in a later post. For fun, let's you can take a look at the C++ code that was generated and JIT compiled during evaluation print ( op . ccode ) #define _POSIX_C_SOURCE 200809L #include \"stdlib.h\" #include \"math.h\" #include \"sys/time.h\" #include \"xmmintrin.h\" #include \"pmmintrin.h\" struct profile { double section_0 ; double section_1 ; } ; int Kernel ( float * restrict V_vec , float * restrict X_vec , const float dt , const float h_x , const int t_size , const int t_s , const int t_e , const int time_size , const int time_s , const int time_e , const int x_size , const int x_s , const int x_e , void * _timings ) { float ( * restrict V )[ x_size ] __attribute__ (( aligned ( 64 ))) = ( float ( * )[ x_size ]) V_vec ; float ( * restrict X ) __attribute__ (( aligned ( 64 ))) = ( float ( * )) X_vec ; struct profile * timings = ( struct profile * ) _timings ; /* Flush denormal numbers to zero in hardware */ _MM_SET_DENORMALS_ZERO_MODE ( _MM_DENORMALS_ZERO_ON ); _MM_SET_FLUSH_ZERO_MODE ( _MM_FLUSH_ZERO_ON ); struct timeval start_section_1 , end_section_1 ; gettimeofday ( & start_section_1 , NULL ); for ( int time = t_s , t0 = ( time ) % ( 2 ), t1 = ( time + 1 ) % ( 2 ); time < t_e - 1 ; time += 1 , t0 = ( time ) % ( 2 ), t1 = ( time + 1 ) % ( 2 )) { for ( int x = x_s + 1 ; x < x_e - 1 ; x += 1 ) { V [ t1 ][ x ] = ( 2.5e-2 F * dt * h_x * ( - V [ t0 ][ x - 1 ] + V [ t0 ][ x + 1 ]) * X [ x ] + 2.0e-2 F * dt * ( X [ x ] * X [ x ]) * ( - 2.0F * V [ t0 ][ x ] + V [ t0 ][ x - 1 ] + V [ t0 ][ x + 1 ]) + 5.0e-2 F * ( h_x * h_x ) * ( - dt + 2.0e+1 F ) * V [ t0 ][ x ]) / pow ( h_x , 2 ); } V [ t1 ][ 0 ] = 9.97222222222222e-1 F * V [ t0 ][ 0 ]; V [ t1 ][ - 1 ] = - V [ t1 ][ - 3 ] + 2 * V [ t1 ][ - 2 ]; } gettimeofday ( & end_section_1 , NULL ); timings -> section_1 += ( double )( end_section_1 . tv_sec - start_section_1 . tv_sec ) + ( double )( end_section_1 . tv_usec - start_section_1 . tv_usec ) / 1000000 ; return 0 ; } Conclusion In this post we solved Black Scholes equation using finite difference methods in both Numpy and Devito. As you can see, their output is similar but their implementation is different. The great thing about Devito is that it allows users to build complex stencils and solve pde's without having to worry about hand writing optimized C++ code. This achieves a nice seperation of concerns between model building in Python and numerical implemenation in C++. In future posts, I plan on implementing more finance models in Devito and comparing Devito's performance with conventional pricing libraries like QuantLib. Until then, thanks for visiting my blog. See you next time. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; var configscript = document.createElement('script'); configscript.type = 'text/x-mathjax-config'; configscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" availableFonts: ['STIX', 'TeX'],\" + \" preferredFont: 'STIX',\" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript); (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"Finance","url":"/devito-and-option-pricing.html","loc":"/devito-and-option-pricing.html"}]};